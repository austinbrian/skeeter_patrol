{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "weather = pd.read_csv('../data/input/weather.csv')\n",
    "test = pd.read_csv('../data/input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reducing the list of columns in weather\n",
    "weather_excluded = ['Depth', 'Water1', 'SnowFall', 'Depart', 'Heat', 'Cool', 'Sunrise', 'Sunset']\n",
    "weather_keep = [column for column in weather.columns if column not in weather_excluded]\n",
    "weather = weather[weather_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dates to date objects\n",
    "weather.Date = pd.DatetimeIndex(weather.Date)\n",
    "test.Date = pd.to_datetime(test.Date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to remove the leading spaces\n",
    "weather.PrecipTotal = weather.PrecipTotal.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at daily data, some dates have an \"M\" or a &\"T\" in the field. What does this mean?\n",
    "\"M\" stands for \"Missing\". Data for an element will be missing if the primary sensor for that weather element is inoperable (e.g., has an outage) or malfunctioning (e.g., producing errant data) AND any collocated backup sensor is also inoperable or malfunctioning. \"T\" stand for \"Trace\". This is a small amount of precipitation that will wet a raingage but is less than the 0.01 inch measuring limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather = weather.replace('T', 0.005)\n",
    "weather = weather.replace('M', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "test.Date = pd.to_datetime(test.Date)\n",
    "cols = [i for i in test.columns]\n",
    "for i,v in enumerate(cols):\n",
    "    if '_date-1_date-' in v: # drops out the repeated date column\n",
    "        test.drop(v,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Formula for calculating compass bearing between two lat/lon tuples.  Credit:  https://gist.github.com/jeromer/2005586\n",
    "Corrected output error in which returned bearing (in degrees) needed to be subtracted from 360 in order to be correct.  \n",
    "Validated this change on https://www.sunearthtools.com/tools/distance.php and with manual orienteering using Google \n",
    "maps in place of a physical map.\n",
    "\n",
    "Other than that change at the end of the formula, the code was taken from the gist page linked above.\n",
    "'''\n",
    "\n",
    "\n",
    "def compass_bearing(loc1, loc2):\n",
    "    \"\"\"\n",
    "    Calculates the bearing between two points.\n",
    "    The formulae used is the following:\n",
    "        θ = atan2(sin(Δlong).cos(lat2),\n",
    "                  cos(lat1).sin(lat2) − sin(lat1).cos(lat2).cos(Δlong))\n",
    "    :Parameters:\n",
    "      - `loc1: The tuple representing the latitude/longitude for the\n",
    "        first point. Latitude and longitude must be in decimal degrees\n",
    "      - `loc2: The tuple representing the latitude/longitude for the\n",
    "        second point. Latitude and longitude must be in decimal degrees\n",
    "    :Returns:\n",
    "      The bearing in degrees\n",
    "    :Returns Type:\n",
    "      float\n",
    "    \"\"\"\n",
    "    if (type(loc1) != tuple) or (type(loc2) != tuple):\n",
    "        raise TypeError(\"Only tuples are supported as arguments\")\n",
    "\n",
    "    lat1 = math.radians(loc1[0])\n",
    "    lat2 = math.radians(loc2[0])\n",
    "\n",
    "    diffLong = math.radians(loc1[1] - loc2[1])\n",
    "\n",
    "    x = math.sin(diffLong) * math.cos(lat2)\n",
    "    y = math.cos(lat1) * math.sin(lat2) - (math.sin(lat1)\n",
    "            * math.cos(lat2) * math.cos(diffLong))\n",
    "\n",
    "    initial_bearing = math.atan2(x, y)\n",
    "\n",
    "    # Now we have the initial bearing but math.atan2 return values\n",
    "    # from -180° to + 180° which is not what we want for a compass bearing\n",
    "    # The solution is to normalize the initial bearing as shown below\n",
    "    initial_bearing = math.degrees(initial_bearing)\n",
    "    compass_bearing = 360 - ((initial_bearing + 360) % 360) ## Mike: this originally returned an incorrect bearing\n",
    "                         ## corrected by subtracting result from 360\n",
    "\n",
    "    return compass_bearing\n",
    "\n",
    "''' \n",
    "Calculate distance in KM between two sets of coordinates (lat/lon tuples).  Uses Haversine formula.  Credit to https://gist.github.com/rochacbruno/2883505 and http://www.movable-type.co.uk/scripts/latlong.html\n",
    "\n",
    "This formula works as-is.  I tested it using Google Maps distance calculator as a validator.\n",
    "'''\n",
    "\n",
    "def distance(loc1, loc2):\n",
    "#     print (loc1, loc2)\n",
    "    lat1, lon1 = loc1\n",
    "    lat2, lon2 = loc2\n",
    "    radius = 6371 # radius of Earth in KM\n",
    "\n",
    "    dlat = math.radians(lat2-lat1)\n",
    "    dlon = math.radians(lon2-lon1)\n",
    "    a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \\\n",
    "        * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "    d = radius * c\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Mapping of each trap to its nearest weather station--compares distance in km between a trap and each airport weather station, and returns the station number ('Station' column) of the nearest weather station.\n",
    "\n",
    "Weather station info from Kaggle:\n",
    "\n",
    "Station 1: CHICAGO O'HARE INTERNATIONAL AIRPORT Lat: 41.995 Lon: -87.933 Elev: 662 ft. above sea level\n",
    "Station 2: CHICAGO MIDWAY INTL ARPT Lat: 41.786 Lon: -87.752 Elev: 612 ft. above sea level\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "station_coords = {\n",
    "        1: (41.995,-87.933),\n",
    "           2: (41.786,-87.752)}\n",
    "\n",
    "test['Coordinates'] = test[['Latitude', 'Longitude']].apply(tuple, axis=1)\n",
    "\n",
    "def assign_station(i):\n",
    "    if distance(station_coords[1], i) < distance(station_coords[2], i):\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "test['Weather_Station'] = test.Coordinates.apply(assign_station)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[test['Coordinates'] == (41.992478000000006, -87.862994999999998), 'Trap'] = 'T009Alt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back to Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_types = {\n",
    "'\\+FC': 'TORNADO/WATERSPOUT','FC': 'FUNNEL CLOUD','TS': 'THUNDERSTORM','GR': 'HAIL','RA': 'RAIN',\n",
    "'DZ': 'DRIZZLE','SN': 'SNOW','SG': 'SNOW GRAINS','GS': 'SMALL HAIL ANDOR SNOW PELLETS','PL': 'ICE PELLETS',\n",
    "'IC': 'ICE CRYSTALS','FG\\+': 'HEAVY FOG','FG': 'FOG','BR': 'MIST','UP': \"UNKNOWN PRECIPITATION\",'HZ': 'HAZE','FU': 'SMOKE',\n",
    "'VA': 'VOLCANIC ASH','DU': 'WIDESPREAD DUST','DS': 'DUSTSTORM','PO': 'SAND_DUST WHIRLS',\n",
    "'SA': 'SAND','SS': 'SANDSTORM','PY': 'SPRAY','SQ': 'SQUALL','DR': 'LOW DRIFTING','SH': 'SHOWER','FZ': 'FREEZING',\n",
    "'MI': 'SHALLOW','PR': 'PARTIAL','BC': 'PATCHES','BL': 'BLOWING','VC': 'VICINITY'}\n",
    "\n",
    "for i in weather_types:\n",
    "    weather[i] = 0\n",
    "    weather.loc[weather.CodeSum.str.contains(i) == True,i] = 1\n",
    "\n",
    "weather.drop('CodeSum',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelsanders/anaconda/lib/python2.7/site-packages/pandas/core/indexing.py:297: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/michaelsanders/anaconda/lib/python2.7/site-packages/pandas/core/indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "n_weather = weather.iloc[12:,:]\n",
    "for i in range(1,7): # Hard-coded range of the last 6 days\n",
    "    n_date = \"_date-\"+str(i)\n",
    "    n_weather.loc[:,n_date] = n_weather.Date-pd.DateOffset(i)\n",
    "    n_weather = pd.merge(left=n_weather,right=weather,left_on=[n_date,'Station'],right_on=['Date','Station'],suffixes =('',n_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelsanders/anaconda/lib/python2.7/site-packages/pandas/util/decorators.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Creating de-duped df of traps and coordinates.\n",
    "traps_master = test[['Trap', 'Coordinates']]\n",
    "# Drop duplicates\n",
    "traps_master.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list of column names to use with for loops below\n",
    "trap_cols = traps_master.Trap.tolist() \n",
    "\n",
    "# Create dictionary of Trap IDs and corresponding lat/lon coordinate tuples\n",
    "trap_dict = traps_master.set_index('Trap')['Coordinates'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates dictionary where key is a Trap name, and the value for each is a list of the distances to every other trap.\n",
    "distance_dict = {}\n",
    "for i in trap_cols:\n",
    "    dist_list = []\n",
    "    for k in trap_dict:\n",
    "        dist = distance(trap_dict[k], trap_dict[i])\n",
    "        dist_list.append(dist)\n",
    "    distance_dict[i] = dist_list\n",
    "\n",
    "\n",
    "# Creates dictionary where key is a Trap name, and the value for each is a list of the compass bearings from every other trap.\n",
    "bearing_dict = {}\n",
    "for c in trap_cols:\n",
    "    bearing_list = []\n",
    "    for q in trap_dict:\n",
    "        bearing = compass_bearing(trap_dict[q], trap_dict[c])\n",
    "        bearing_list.append(bearing)\n",
    "    bearing_dict[c] = bearing_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creates df of relative distances.  To be merged with a left join into train df.\n",
    "dist_df = pd.DataFrame.from_dict(distance_dict, orient='index')\n",
    "distance_labels = dist_df.index.tolist()\n",
    "distance_cols = []\n",
    "for c in distance_labels:\n",
    "    label = c + '_dist'\n",
    "    distance_cols.append(label)\n",
    "dist_df.columns = [distance_cols] \n",
    "dist_df['Trap'] = dist_df.index\n",
    "# dist_df.to_csv('../data/relative_locations.csv')\n",
    "\n",
    "\n",
    "# Creates df of relative bearings.  To be merged with a left join into train df.\n",
    "bearing_df = pd.DataFrame.from_dict(bearing_dict, orient='index')  \n",
    "bearing_labels = bearing_df.index.tolist()  \n",
    "bearing_cols = []\n",
    "for c in bearing_labels:\n",
    "    label = c + '_bearing'\n",
    "    bearing_cols.append(label)\n",
    "bearing_df.columns = [bearing_cols]\n",
    "bearing_df['Trap'] = bearing_df.index\n",
    "# bearing_df.to_csv('../data/relative_bearings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.merge(test, dist_df, how='left', left_on='Trap', right_on='Trap')\n",
    "test = pd.merge(test, bearing_df, how='left', left_on='Trap', right_on='Trap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116293, 313)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.merge(test,n_weather,left_on=['Date','Weather_Station'],right_on=['Date','Station'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping mosquitos together to get a more accurate picture of how many mosquitos in each trap\n",
    "# test['Trap_Mosquitos_today'] = test.groupby(['Trap','Date'])['NumMosquitos'].transform('sum')\n",
    "# test['Trap_Species_today'] = test.groupby(['Trap','Date','Species'])['NumMosquitos'].transform('sum')\n",
    "# test['min_Wnv_species_today'] = test.groupby(['Trap','Date','Species'])['WnvPresent'].transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['Epoch'] = test.Date.astype(np.int64) // 10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test.to_csv('~/Dropbox/DSI/test_prepped.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv('../../../../datasets/Project4/workingfiles/test_prepped.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "### Pre-Processing for Model Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_curve, auc\n",
    "from sklearn import svm\n",
    "import hdbscan\n",
    "from sklearn.preprocessing import LabelEncoder,normalize,StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [i for i in test.columns]\n",
    "# deal with NaNs\n",
    "for i in test.columns[test.isnull().sum()>0]: # for all the columns with nans\n",
    "    mean_avg_temp = test.loc[test[i].isnull()==True,'Tavg'].mean() # what is the mean Tavg\n",
    "    mean_i_val = test.loc[test.Tavg==mean_avg_temp,i].mean() # what is i val for that Tavg\n",
    "    test.loc[test[i].isnull()==True,'to_fill'] = mean_i_val\n",
    "    test[i] = test[i].fillna(test.to_fill)\n",
    "    test.drop('to_fill',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop unneeded date columns\n",
    "dates = ['_date-'+str(i) for i in range(1,7)]\n",
    "for i,v in enumerate(cols):\n",
    "    try:\n",
    "        if v in dates: # drops out the repeated date column\n",
    "            test.drop(v,axis=1,inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if 'Date_date-' in v:\n",
    "            test.drop(v,axis=1,inplace=True)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116293, 623)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Label encode the trap names and mosquito names\n",
    "le = LabelEncoder()\n",
    "le.fit(test.Species)\n",
    "test['mosquito'] = le.transform(test.Species)\n",
    "le.fit(test.Trap)\n",
    "test['trap_e'] = le.transform(test.Trap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build list of weather categories that need to be scaled (categorical columns are already dummies)\n",
    "\n",
    "weather_cats = test.columns[300:333].tolist()\n",
    "\n",
    "new_cats = []\n",
    "for c in range(1,7):\n",
    "    for w in weather_cats:\n",
    "        c_string = str(c)\n",
    "        cat = str(w)+'_date-'+c_string\n",
    "        new_cats.append(cat)\n",
    "        \n",
    "weather_cats = weather_cats + new_cats\n",
    "\n",
    "scale_exclude = ['Date', 'mosquito', 'Species', 'Trap', 'trap_e','Address', 'Block', 'Street', \n",
    "               'AddressNumberAndStreet', 'AddressAccuracy', 'Coordinates', 'Weather_Station','Epoch',\n",
    "                'Latitude','Longitude']\n",
    "\n",
    "for c in weather_cats:\n",
    "    scale_exclude.append(c)\n",
    "\n",
    "scale_cols = [x for x in test.columns if x not in scale_exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in test.columns:\n",
    "#     print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop any remaining NaNs\n",
    "# test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scaling all non-categorical numerical values using standard scaler\n",
    "\n",
    "std_scale = StandardScaler()\n",
    "test[scale_cols] = std_scale.fit_transform(test[scale_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import mosquito count regression models\n",
    "linreg_total = joblib.load('../models/linreg_total.pkl')\n",
    "linreg_spec = joblib.load('../models/linreg_spec.pkl')\n",
    "linreg_count = joblib.load('../models/linreg_count.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regression_cols = ['Latitude', 'Longitude', 'Station', 'Tmax', 'Tmin','Tavg', 'DewPoint', 'WetBulb',\n",
    "                           'PrecipTotal', 'StnPressure', 'SeaLevel', 'ResultSpeed', 'ResultDir', 'AvgSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = test[regression_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116293, 14)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "NumMosquitos = linreg_total.predict(X)\n",
    "Total_in_trap = linreg_count.predict(X)\n",
    "Species_count = linreg_spec.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['NumMosquitos'] = NumMosquitos\n",
    "test['Trap_Mosquitos_today'] = Total_in_trap\n",
    "test['Trap_Species_today'] = Species_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_cols = ['Id', 'Date','Address','Species', 'Block', 'Street', 'Trap', 'AddressNumberAndStreet', \n",
    "             'AddressAccuracy', 'Coordinates', 'Weather_Station', 'mosquito','Tavg_date-1',\n",
    " 'SeaLevel_date-1',\n",
    " 'AvgSpeed_date-1',\n",
    " 'Tavg_date-2',\n",
    " 'SeaLevel_date-2',\n",
    " 'AvgSpeed_date-2',\n",
    " 'Tavg_date-3',\n",
    " 'Tavg_date-6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_cols = [i for i in test.columns if i not in mask_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_class_cols = [i for i in class_cols if i in model_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "582"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_class_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_class = test[new_class_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_cols = ['Latitude',\n",
    " 'Longitude',\n",
    " 'NumMosquitos',\n",
    " 'T152_dist',\n",
    " 'T153_dist',\n",
    " 'T019_dist',\n",
    " 'T018_dist',\n",
    " 'T156_dist',\n",
    " 'T157_dist',\n",
    " 'T154_dist',\n",
    " 'T155_dist',\n",
    " 'T013_dist',\n",
    " 'T012_dist',\n",
    " 'T011_dist',\n",
    " 'T159_dist',\n",
    " 'T017_dist',\n",
    " 'T016_dist',\n",
    " 'T015_dist',\n",
    " 'T014_dist',\n",
    " 'T151_dist',\n",
    " 'T080_dist',\n",
    " 'T081_dist',\n",
    " 'T082_dist',\n",
    " 'T083_dist',\n",
    " 'T084_dist',\n",
    " 'T085_dist',\n",
    " 'T086_dist',\n",
    " 'T088_dist',\n",
    " 'T089_dist',\n",
    " 'T158_dist',\n",
    " 'T149_dist',\n",
    " 'T148_dist',\n",
    " 'T009Alt_dist',\n",
    " 'T145_dist',\n",
    " 'T144_dist',\n",
    " 'T147_dist',\n",
    " 'T146_dist',\n",
    " 'T141_dist',\n",
    " 'T143_dist',\n",
    " 'T142_dist',\n",
    " 'T903_dist',\n",
    " 'T092_dist',\n",
    " 'T091_dist',\n",
    " 'T090_dist',\n",
    " 'T097_dist',\n",
    " 'T096_dist',\n",
    " 'T095_dist',\n",
    " 'T094_dist',\n",
    " 'T099_dist',\n",
    " 'T222_dist',\n",
    " 'T138_dist',\n",
    " 'T046_dist',\n",
    " 'T128_dist',\n",
    " 'T114_dist',\n",
    " 'T027_dist',\n",
    " 'T025_dist',\n",
    " 'T228_dist',\n",
    " 'T229_dist',\n",
    " 'T900_dist',\n",
    " 'T224_dist',\n",
    " 'T225_dist',\n",
    " 'T226_dist',\n",
    " 'T227_dist',\n",
    " 'T220_dist',\n",
    " 'T221_dist',\n",
    " 'T028_dist',\n",
    " 'T223_dist',\n",
    " 'T044_dist',\n",
    " 'T045_dist',\n",
    " 'T129_dist',\n",
    " 'T047_dist',\n",
    " 'T040_dist',\n",
    " 'T043_dist',\n",
    " 'T048_dist',\n",
    " 'T049_dist',\n",
    " 'T031_dist',\n",
    " 'T030_dist',\n",
    " 'T033_dist',\n",
    " 'T035_dist',\n",
    " 'T034_dist',\n",
    " 'T037_dist',\n",
    " 'T036_dist',\n",
    " 'T039_dist',\n",
    " 'T236_dist',\n",
    " 'T235_dist',\n",
    " 'T233_dist',\n",
    " 'T232_dist',\n",
    " 'T231_dist',\n",
    " 'T230_dist',\n",
    " 'T054_dist',\n",
    " 'T051_dist',\n",
    " 'T050_dist',\n",
    " 'T209_dist',\n",
    " 'T200_dist',\n",
    " 'T206_dist',\n",
    " 'T062_dist',\n",
    " 'T063_dist',\n",
    " 'T060_dist',\n",
    " 'T061_dist',\n",
    " 'T066_dist',\n",
    " 'T067_dist',\n",
    " 'T065_dist',\n",
    " 'T069_dist',\n",
    " 'T135_dist',\n",
    " 'T054C_dist',\n",
    " 'T238_dist',\n",
    " 'T215_dist',\n",
    " 'T212_dist',\n",
    " 'T219_dist',\n",
    " 'T218_dist',\n",
    " 'T150_dist',\n",
    " 'T115_dist',\n",
    " 'T079_dist',\n",
    " 'T078_dist',\n",
    " 'T075_dist',\n",
    " 'T074_dist',\n",
    " 'T077_dist',\n",
    " 'T076_dist',\n",
    " 'T071_dist',\n",
    " 'T070_dist',\n",
    " 'T073_dist',\n",
    " 'T072_dist',\n",
    " 'T094B_dist',\n",
    " 'T100_dist',\n",
    " 'T103_dist',\n",
    " 'T102_dist',\n",
    " 'T107_dist',\n",
    " 'T008_dist',\n",
    " 'T009_dist',\n",
    " 'T162_dist',\n",
    " 'T161_dist',\n",
    " 'T160_dist',\n",
    " 'T001_dist',\n",
    " 'T002_dist',\n",
    " 'T003_dist',\n",
    " 'T004_dist',\n",
    " 'T005_dist',\n",
    " 'T006_dist',\n",
    " 'T007_dist',\n",
    " 'T237_dist',\n",
    " 'T152_bearing',\n",
    " 'T153_bearing',\n",
    " 'T019_bearing',\n",
    " 'T018_bearing',\n",
    " 'T156_bearing',\n",
    " 'T157_bearing',\n",
    " 'T154_bearing',\n",
    " 'T155_bearing',\n",
    " 'T013_bearing',\n",
    " 'T012_bearing',\n",
    " 'T011_bearing',\n",
    " 'T159_bearing',\n",
    " 'T017_bearing',\n",
    " 'T016_bearing',\n",
    " 'T015_bearing',\n",
    " 'T014_bearing',\n",
    " 'T151_bearing',\n",
    " 'T080_bearing',\n",
    " 'T081_bearing',\n",
    " 'T082_bearing',\n",
    " 'T083_bearing',\n",
    " 'T084_bearing',\n",
    " 'T085_bearing',\n",
    " 'T086_bearing',\n",
    " 'T088_bearing',\n",
    " 'T089_bearing',\n",
    " 'T158_bearing',\n",
    " 'T149_bearing',\n",
    " 'T148_bearing',\n",
    " 'T009Alt_bearing',\n",
    " 'T145_bearing',\n",
    " 'T144_bearing',\n",
    " 'T147_bearing',\n",
    " 'T146_bearing',\n",
    " 'T141_bearing',\n",
    " 'T143_bearing',\n",
    " 'T142_bearing',\n",
    " 'T903_bearing',\n",
    " 'T092_bearing',\n",
    " 'T091_bearing',\n",
    " 'T090_bearing',\n",
    " 'T097_bearing',\n",
    " 'T096_bearing',\n",
    " 'T095_bearing',\n",
    " 'T094_bearing',\n",
    " 'T099_bearing',\n",
    " 'T222_bearing',\n",
    " 'T138_bearing',\n",
    " 'T046_bearing',\n",
    " 'T128_bearing',\n",
    " 'T114_bearing',\n",
    " 'T027_bearing',\n",
    " 'T025_bearing',\n",
    " 'T228_bearing',\n",
    " 'T229_bearing',\n",
    " 'T900_bearing',\n",
    " 'T224_bearing',\n",
    " 'T225_bearing',\n",
    " 'T226_bearing',\n",
    " 'T227_bearing',\n",
    " 'T220_bearing',\n",
    " 'T221_bearing',\n",
    " 'T028_bearing',\n",
    " 'T223_bearing',\n",
    " 'T044_bearing',\n",
    " 'T045_bearing',\n",
    " 'T129_bearing',\n",
    " 'T047_bearing',\n",
    " 'T040_bearing',\n",
    " 'T043_bearing',\n",
    " 'T048_bearing',\n",
    " 'T049_bearing',\n",
    " 'T031_bearing',\n",
    " 'T030_bearing',\n",
    " 'T033_bearing',\n",
    " 'T035_bearing',\n",
    " 'T034_bearing',\n",
    " 'T037_bearing',\n",
    " 'T036_bearing',\n",
    " 'T039_bearing',\n",
    " 'T236_bearing',\n",
    " 'T235_bearing',\n",
    " 'T233_bearing',\n",
    " 'T232_bearing',\n",
    " 'T231_bearing',\n",
    " 'T230_bearing',\n",
    " 'T054_bearing',\n",
    " 'T051_bearing',\n",
    " 'T050_bearing',\n",
    " 'T209_bearing',\n",
    " 'T200_bearing',\n",
    " 'T206_bearing',\n",
    " 'T062_bearing',\n",
    " 'T063_bearing',\n",
    " 'T060_bearing',\n",
    " 'T061_bearing',\n",
    " 'T066_bearing',\n",
    " 'T067_bearing',\n",
    " 'T065_bearing',\n",
    " 'T069_bearing',\n",
    " 'T135_bearing',\n",
    " 'T054C_bearing',\n",
    " 'T238_bearing',\n",
    " 'T215_bearing',\n",
    " 'T212_bearing',\n",
    " 'T219_bearing',\n",
    " 'T218_bearing',\n",
    " 'T150_bearing',\n",
    " 'T115_bearing',\n",
    " 'T079_bearing',\n",
    " 'T078_bearing',\n",
    " 'T075_bearing',\n",
    " 'T074_bearing',\n",
    " 'T077_bearing',\n",
    " 'T076_bearing',\n",
    " 'T071_bearing',\n",
    " 'T070_bearing',\n",
    " 'T073_bearing',\n",
    " 'T072_bearing',\n",
    " 'T094B_bearing',\n",
    " 'T100_bearing',\n",
    " 'T103_bearing',\n",
    " 'T102_bearing',\n",
    " 'T107_bearing',\n",
    " 'T008_bearing',\n",
    " 'T009_bearing',\n",
    " 'T162_bearing',\n",
    " 'T161_bearing',\n",
    " 'T160_bearing',\n",
    " 'T001_bearing',\n",
    " 'T002_bearing',\n",
    " 'T003_bearing',\n",
    " 'T004_bearing',\n",
    " 'T005_bearing',\n",
    " 'T006_bearing',\n",
    " 'T007_bearing',\n",
    " 'T237_bearing',\n",
    " 'Station',\n",
    " 'Tmax',\n",
    " 'Tmin',\n",
    " 'Tavg',\n",
    " 'DewPoint',\n",
    " 'WetBulb',\n",
    " 'PrecipTotal',\n",
    " 'StnPressure',\n",
    " 'SeaLevel',\n",
    " 'ResultSpeed',\n",
    " 'ResultDir',\n",
    " 'AvgSpeed',\n",
    " 'HZ',\n",
    " 'VA',\n",
    " 'VC',\n",
    " 'GS',\n",
    " 'GR',\n",
    " 'FG\\\\+',\n",
    " 'BC',\n",
    " 'BL',\n",
    " 'FZ',\n",
    " 'UP',\n",
    " 'FC',\n",
    " 'DZ',\n",
    " 'BR',\n",
    " 'FG',\n",
    " 'IC',\n",
    " 'DU',\n",
    " 'DR',\n",
    " 'DS',\n",
    " 'FU',\n",
    " 'PR',\n",
    " 'SS',\n",
    " 'SQ',\n",
    " 'PY',\n",
    " 'MI',\n",
    " 'TS',\n",
    " 'SH',\n",
    " 'RA',\n",
    " '\\\\+FC',\n",
    " 'SA',\n",
    " 'SG',\n",
    " 'PO',\n",
    " 'PL',\n",
    " 'SN',\n",
    " 'Tmax_date-1',\n",
    " 'Tmin_date-1',\n",
    " 'Tavg_date-1',\n",
    " 'DewPoint_date-1',\n",
    " 'WetBulb_date-1',\n",
    " 'PrecipTotal_date-1',\n",
    " 'StnPressure_date-1',\n",
    " 'SeaLevel_date-1',\n",
    " 'ResultSpeed_date-1',\n",
    " 'ResultDir_date-1',\n",
    " 'AvgSpeed_date-1',\n",
    " 'HZ_date-1',\n",
    " 'VA_date-1',\n",
    " 'VC_date-1',\n",
    " 'GS_date-1',\n",
    " 'GR_date-1',\n",
    " 'FG\\\\+_date-1',\n",
    " 'BC_date-1',\n",
    " 'BL_date-1',\n",
    " 'FZ_date-1',\n",
    " 'UP_date-1',\n",
    " 'FC_date-1',\n",
    " 'DZ_date-1',\n",
    " 'BR_date-1',\n",
    " 'FG_date-1',\n",
    " 'IC_date-1',\n",
    " 'DU_date-1',\n",
    " 'DR_date-1',\n",
    " 'DS_date-1',\n",
    " 'FU_date-1',\n",
    " 'PR_date-1',\n",
    " 'SS_date-1',\n",
    " 'SQ_date-1',\n",
    " 'PY_date-1',\n",
    " 'MI_date-1',\n",
    " 'TS_date-1',\n",
    " 'SH_date-1',\n",
    " 'RA_date-1',\n",
    " '\\\\+FC_date-1',\n",
    " 'SA_date-1',\n",
    " 'SG_date-1',\n",
    " 'PO_date-1',\n",
    " 'PL_date-1',\n",
    " 'SN_date-1',\n",
    " 'Tmax_date-2',\n",
    " 'Tmin_date-2',\n",
    " 'Tavg_date-2',\n",
    " 'DewPoint_date-2',\n",
    " 'WetBulb_date-2',\n",
    " 'PrecipTotal_date-2',\n",
    " 'StnPressure_date-2',\n",
    " 'SeaLevel_date-2',\n",
    " 'ResultSpeed_date-2',\n",
    " 'ResultDir_date-2',\n",
    " 'AvgSpeed_date-2',\n",
    " 'HZ_date-2',\n",
    " 'VA_date-2',\n",
    " 'VC_date-2',\n",
    " 'GS_date-2',\n",
    " 'GR_date-2',\n",
    " 'FG\\\\+_date-2',\n",
    " 'BC_date-2',\n",
    " 'BL_date-2',\n",
    " 'FZ_date-2',\n",
    " 'UP_date-2',\n",
    " 'FC_date-2',\n",
    " 'DZ_date-2',\n",
    " 'BR_date-2',\n",
    " 'FG_date-2',\n",
    " 'IC_date-2',\n",
    " 'DU_date-2',\n",
    " 'DR_date-2',\n",
    " 'DS_date-2',\n",
    " 'FU_date-2',\n",
    " 'PR_date-2',\n",
    " 'SS_date-2',\n",
    " 'SQ_date-2',\n",
    " 'PY_date-2',\n",
    " 'MI_date-2',\n",
    " 'TS_date-2',\n",
    " 'SH_date-2',\n",
    " 'RA_date-2',\n",
    " '\\\\+FC_date-2',\n",
    " 'SA_date-2',\n",
    " 'SG_date-2',\n",
    " 'PO_date-2',\n",
    " 'PL_date-2',\n",
    " 'SN_date-2',\n",
    " 'Tmax_date-3',\n",
    " 'Tmin_date-3',\n",
    " 'Tavg_date-3',\n",
    " 'DewPoint_date-3',\n",
    " 'WetBulb_date-3',\n",
    " 'PrecipTotal_date-3',\n",
    " 'StnPressure_date-3',\n",
    " 'SeaLevel_date-3',\n",
    " 'ResultSpeed_date-3',\n",
    " 'ResultDir_date-3',\n",
    " 'AvgSpeed_date-3',\n",
    " 'HZ_date-3',\n",
    " 'VA_date-3',\n",
    " 'VC_date-3',\n",
    " 'GS_date-3',\n",
    " 'GR_date-3',\n",
    " 'FG\\\\+_date-3',\n",
    " 'BC_date-3',\n",
    " 'BL_date-3',\n",
    " 'FZ_date-3',\n",
    " 'UP_date-3',\n",
    " 'FC_date-3',\n",
    " 'DZ_date-3',\n",
    " 'BR_date-3',\n",
    " 'FG_date-3',\n",
    " 'IC_date-3',\n",
    " 'DU_date-3',\n",
    " 'DR_date-3',\n",
    " 'DS_date-3',\n",
    " 'FU_date-3',\n",
    " 'PR_date-3',\n",
    " 'SS_date-3',\n",
    " 'SQ_date-3',\n",
    " 'PY_date-3',\n",
    " 'MI_date-3',\n",
    " 'TS_date-3',\n",
    " 'SH_date-3',\n",
    " 'RA_date-3',\n",
    " '\\\\+FC_date-3',\n",
    " 'SA_date-3',\n",
    " 'SG_date-3',\n",
    " 'PO_date-3',\n",
    " 'PL_date-3',\n",
    " 'SN_date-3',\n",
    " 'Tmax_date-4',\n",
    " 'Tmin_date-4',\n",
    " 'Tavg_date-4',\n",
    " 'DewPoint_date-4',\n",
    " 'WetBulb_date-4',\n",
    " 'PrecipTotal_date-4',\n",
    " 'StnPressure_date-4',\n",
    " 'SeaLevel_date-4',\n",
    " 'ResultSpeed_date-4',\n",
    " 'ResultDir_date-4',\n",
    " 'AvgSpeed_date-4',\n",
    " 'HZ_date-4',\n",
    " 'VA_date-4',\n",
    " 'VC_date-4',\n",
    " 'GS_date-4',\n",
    " 'GR_date-4',\n",
    " 'FG\\\\+_date-4',\n",
    " 'BC_date-4',\n",
    " 'BL_date-4',\n",
    " 'FZ_date-4',\n",
    " 'UP_date-4',\n",
    " 'FC_date-4',\n",
    " 'DZ_date-4',\n",
    " 'BR_date-4',\n",
    " 'FG_date-4',\n",
    " 'IC_date-4',\n",
    " 'DU_date-4',\n",
    " 'DR_date-4',\n",
    " 'DS_date-4',\n",
    " 'FU_date-4',\n",
    " 'PR_date-4',\n",
    " 'SS_date-4',\n",
    " 'SQ_date-4',\n",
    " 'PY_date-4',\n",
    " 'MI_date-4',\n",
    " 'TS_date-4',\n",
    " 'SH_date-4',\n",
    " 'RA_date-4',\n",
    " '\\\\+FC_date-4',\n",
    " 'SA_date-4',\n",
    " 'SG_date-4',\n",
    " 'PO_date-4',\n",
    " 'PL_date-4',\n",
    " 'SN_date-4',\n",
    " 'Tmax_date-5',\n",
    " 'Tmin_date-5',\n",
    " 'Tavg_date-5',\n",
    " 'DewPoint_date-5',\n",
    " 'WetBulb_date-5',\n",
    " 'PrecipTotal_date-5',\n",
    " 'StnPressure_date-5',\n",
    " 'SeaLevel_date-5',\n",
    " 'ResultSpeed_date-5',\n",
    " 'ResultDir_date-5',\n",
    " 'AvgSpeed_date-5',\n",
    " 'HZ_date-5',\n",
    " 'VA_date-5',\n",
    " 'VC_date-5',\n",
    " 'GS_date-5',\n",
    " 'GR_date-5',\n",
    " 'FG\\\\+_date-5',\n",
    " 'BC_date-5',\n",
    " 'BL_date-5',\n",
    " 'FZ_date-5',\n",
    " 'UP_date-5',\n",
    " 'FC_date-5',\n",
    " 'DZ_date-5',\n",
    " 'BR_date-5',\n",
    " 'FG_date-5',\n",
    " 'IC_date-5',\n",
    " 'DU_date-5',\n",
    " 'DR_date-5',\n",
    " 'DS_date-5',\n",
    " 'FU_date-5',\n",
    " 'PR_date-5',\n",
    " 'SS_date-5',\n",
    " 'SQ_date-5',\n",
    " 'PY_date-5',\n",
    " 'MI_date-5',\n",
    " 'TS_date-5',\n",
    " 'SH_date-5',\n",
    " 'RA_date-5',\n",
    " '\\\\+FC_date-5',\n",
    " 'SA_date-5',\n",
    " 'SG_date-5',\n",
    " 'PO_date-5',\n",
    " 'PL_date-5',\n",
    " 'SN_date-5',\n",
    " 'Tmax_date-6',\n",
    " 'Tmin_date-6',\n",
    " 'Tavg_date-6',\n",
    " 'DewPoint_date-6',\n",
    " 'WetBulb_date-6',\n",
    " 'PrecipTotal_date-6',\n",
    " 'StnPressure_date-6',\n",
    " 'SeaLevel_date-6',\n",
    " 'ResultSpeed_date-6',\n",
    " 'ResultDir_date-6',\n",
    " 'AvgSpeed_date-6',\n",
    " 'HZ_date-6',\n",
    " 'VA_date-6',\n",
    " 'VC_date-6',\n",
    " 'GS_date-6',\n",
    " 'GR_date-6',\n",
    " 'FG\\\\+_date-6',\n",
    " 'BC_date-6',\n",
    " 'BL_date-6',\n",
    " 'FZ_date-6',\n",
    " 'UP_date-6',\n",
    " 'FC_date-6',\n",
    " 'DZ_date-6',\n",
    " 'BR_date-6',\n",
    " 'FG_date-6',\n",
    " 'IC_date-6',\n",
    " 'DU_date-6',\n",
    " 'DR_date-6',\n",
    " 'DS_date-6',\n",
    " 'FU_date-6',\n",
    " 'PR_date-6',\n",
    " 'SS_date-6',\n",
    " 'SQ_date-6',\n",
    " 'PY_date-6',\n",
    " 'MI_date-6',\n",
    " 'TS_date-6',\n",
    " 'SH_date-6',\n",
    " 'RA_date-6',\n",
    " '\\\\+FC_date-6',\n",
    " 'SA_date-6',\n",
    " 'SG_date-6',\n",
    " 'PO_date-6',\n",
    " 'PL_date-6',\n",
    " 'SN_date-6',\n",
    " 'Trap_Mosquitos_today',\n",
    " 'Trap_Species_today',\n",
    " 'Epoch',\n",
    " 'trap_e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=31,svd_solver='full') # 30 components describe 85% of variance\n",
    "# pca.fit(X_class)\n",
    "# X_pca = pca.transform(X_class)\n",
    "# print pca.explained_variance_ratio_\n",
    "# print pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_csv('../data/input/sampleSubmission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.drop('WnvPresent', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_cols = X_class.columns[X_class.isnull().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tavg_date-1',\n",
       " 'SeaLevel_date-1',\n",
       " 'AvgSpeed_date-1',\n",
       " 'Tavg_date-2',\n",
       " 'SeaLevel_date-2',\n",
       " 'AvgSpeed_date-2',\n",
       " 'Tavg_date-3',\n",
       " 'Tavg_date-6']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_class['Tavg_date-1'] = pd.to_numeric(X_class['Tavg_date-1'], errors='coerce')\n",
    "# X_class['SeaLevel_date-1'] = pd.to_numeric(X_class['SeaLevel_date-1'], errors='coerce')\n",
    "# X_class['AvgSpeed_date-1'] = pd.to_numeric(X_class['AvgSpeed_date-1'], errors='coerce')\n",
    "# X_class['Tavg_date-2'] = pd.to_numeric(X_class['Tavg_date-2'], errors='coerce')\n",
    "# X_class['SeaLevel_date-2'] = pd.to_numeric(X_class['SeaLevel_date-2'], errors='coerce')\n",
    "# X_class['AvgSpeed_date-2'] = pd.to_numeric(X_class['AvgSpeed_date-2'], errors='coerce')\n",
    "# X_class['Tavg_date-3'] = pd.to_numeric(X_class['Tavg_date-3'], errors='coerce')\n",
    "# X_class['Tavg_date-6'] = pd.to_numeric(X_class['Tavg_date-6'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tavg_date-1',\n",
       " 'SeaLevel_date-1',\n",
       " 'AvgSpeed_date-1',\n",
       " 'Tavg_date-2',\n",
       " 'SeaLevel_date-2',\n",
       " 'AvgSpeed_date-2',\n",
       " 'Tavg_date-3',\n",
       " 'Tavg_date-6']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_class.columns[X_class.isnull().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_class['Tavg_date-1'].fillna(X_class['Tavg_date-1'].mode, inplace=True)\n",
    "# X_class['SeaLevel_date-1'].fillna(X_class['SeaLevel_date-1'].mode, inplace=True)\n",
    "# X_class['AvgSpeed_date-1'].fillna(X_class['AvgSpeed_date-1'].mode, inplace=True)\n",
    "# X_class['Tavg_date-2'].fillna(X_class['Tavg_date-2'].mode, inplace=True)\n",
    "# X_class['SeaLevel_date-2'].fillna(X_class['SeaLevel_date-2'].mode, inplace=True)\n",
    "# X_class['AvgSpeed_date-2'].fillna(X_class['AvgSpeed_date-2'].mode, inplace=True)\n",
    "# X_class['Tavg_date-3'].fillna(X_class['Tavg_date-3'].mode, inplace=True)\n",
    "# X_class['Tavg_date-6'].fillna(X_class['Tavg_date-6'].mode, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import classifiers\n",
    "ada = joblib.load('../models/ada0427.pkl')\n",
    "RF = joblib.load('../models/RF0427.pkl')\n",
    "SVM = joblib.load('../models/SVM0427.pkl') \n",
    "GB =  joblib.load('../models/GB0427.pkl')\n",
    "XGB = joblib.load('../models/XGB0427.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_predict = ada.predict_proba(X_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_predict = RF.predict_proba(X_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_predict = SVM.predict_proba(X_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_predict = GB.predict_proba(X_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGB_predict = XGB.predict_proba(X_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ada_wnv_preds = [i[1] for i in ada_predict]\n",
    "Ada_submission = output.copy()\n",
    "Ada_submission['WnvPresent'] = Ada_wnv_preds\n",
    "Ada_submission.to_csv('../submissions/ada0427.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RF_wnv_preds = [i[1] for i in RF_predict]\n",
    "RF_submission = output.copy()\n",
    "RF_submission['WnvPresent'] = RF_wnv_preds\n",
    "RF_submission.to_csv('../submissions/RF0427.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SVM_wnv_preds = [i[1] for i in SVM_predict]\n",
    "SVM_submission = output.copy()\n",
    "SVM_submission['WnvPresent'] = SVM_wnv_preds\n",
    "SVM_submission.to_csv('../submissions/SVM0427.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GB_wnv_preds = [i[1] for i in GB_predict]\n",
    "GB_submission = output.copy()\n",
    "GB_submission['WnvPresent'] = GB_wnv_preds\n",
    "GB_submission.to_csv('../submissions/GB0427.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>WnvPresent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.711199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.711199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.711199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.711199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.711199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  WnvPresent\n",
       "0   1    0.711199\n",
       "1   2    0.711199\n",
       "2   3    0.711199\n",
       "3   4    0.711199\n",
       "4   5    0.711199"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>WnvPresent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.050955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.050955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.050955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.050955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.050955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  WnvPresent\n",
       "0   1    0.050955\n",
       "1   2    0.050955\n",
       "2   3    0.050955\n",
       "3   4    0.050955\n",
       "4   5    0.050955"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVM_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>WnvPresent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  WnvPresent\n",
       "0   1         0.5\n",
       "1   2         0.5\n",
       "2   3         0.5\n",
       "3   4         0.5\n",
       "4   5         0.5"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>WnvPresent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.296632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.296632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.296632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.296632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.296632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  WnvPresent\n",
       "0   1    0.296632\n",
       "1   2    0.296632\n",
       "2   3    0.296632\n",
       "3   4    0.296632\n",
       "4   5    0.296632"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ada_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
